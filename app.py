import streamlit as st
from google import genai

st.set_page_config(page_title="A&R Flash", page_icon="๐ฅ", layout="centered")

st.title("๐ฅ A&R Flash")
st.caption("AI Trend Scout for Arabic Pop (V1)")

# --- Secrets ---
API_KEY = st.secrets.get("GEMINI_API_KEY", "")
if not API_KEY:
    st.error("Missing GEMINI_API_KEY in Streamlit Secrets. Go to Manage app โ Settings โ Secrets.")
    st.stop()

client = genai.Client(api_key=API_KEY)
MODEL = "gemini-2.5-flash"

# --- UI ---
brief = st.text_area(
    "ุงูุชุจ brief ุณุฑูุน (ููุถูุน/ููุฑุฉ/ุฌูููุฑ/ูุฒุงุฌ):",
    placeholder="ูุซุงู: ุฃุบููุฉ ุจูุจ ุนุฑุจูุฉ ููุดุจุงุจ 17-24 ุนู ูุณุฑ ุงูุฑูุชููุ ุทุงูุฉ ููุฑุญุ ููุงุณุจุฉ ูุชูู ุชูู.",
    height=120
)

col1, col2 = st.columns(2)
with col1:
    n_ideas = st.slider("ุนุฏุฏ ุงูุฃููุงุฑ", 5, 20, 10)
with col2:
    temp = st.slider("ุงูู Temperature", 0.0, 1.0, 0.7)

generate = st.button("โก Generate", use_container_width=True)

# --- Prompt template ---
def build_prompt(user_brief: str, ideas: int) -> str:
    return f"""
ุฃูุช ูุฑูู A&R ูุญุชุฑู (Trend Scout + A&R Judge). ุงูุชุจ ุจุงูุนุฑุจูุฉ ููุท.

ุงููุทููุจ:
1) ูููุฏ {ideas} ุฃููุงุฑ ูุฃุบุงูู ุจูุจ ุนุฑุจูุฉ ุฌุฏูุฏุฉ ูููุงุณุจุฉ ูุชูู ุชูู (ููุดุจุงุจ 17-24).
ููู ููุฑุฉ ุงูุชุจ:
- Title (ุนููุงู)
- Core Emotion (ุงููุดุงุนุฑ ุงูุฃุณุงุณูุฉ)
- Hook sentence (ุณุทุฑ ุนุฑุจู ูุตูุฑ โูุงุฒู ูุนููโ)
- BPM suggestion
- Production vibe (ูุตู ุฅูุชุงุฌ/ุฌููุฑุง/ุฅููุงุน)

2) ุจุนุฏูุง ูููู ุงูุฃููุงุฑ ูุงุฎุชุฑ ุฃูุถู 3 ูู ูุงุญูุฉ:
TikTok potential / Live performance / Spotify replay
ูุงุนุทู ููู ูุงุญุฏุฉ:
- Score ูู 10 ููู ุจูุฏ (3 ุจููุฏ)
- ุณุจุจ ุณุฑูุน
- Production brief ูุฎุชุตุฑ (ููุงูุญ ุชูุฒูุน/ุตูุช/ูููู ููุฑุณ)

ุงูู Brief ูู ุงููุณุชุฎุฏู:
{user_brief}
""".strip()

if generate:
    if not brief.strip():
        st.warning("ุงูุชุจ brief ุตุบูุฑ ูุจู ูุง ููููุฏ ุงูุฃููุงุฑ.")
        st.stop()

    prompt = build_prompt(brief.strip(), n_ideas)

    with st.spinner("ุนู ูุทุจุฎ ุฃููุงุฑโฆ ๐ฅ"):
        resp = client.models.generate_content(
            model=MODEL,
            contents=prompt,
            config={"temperature": temp}
        )

    st.subheader("ุงููุชูุฌุฉ")
    st.write(resp.text)
